import streamlit as st
import io
import json
import time
import random
from datetime import datetime
import smtplib
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText

try:
    from transformers import pipeline
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False
    st.warning("Transformers not available. Using fallback responses.")

try:
    import plotly.express as px
    import pandas as pd
    PLOTLY_AVAILABLE = True
except ImportError:
    PLOTLY_AVAILABLE = False

PDF_AVAILABLE = False
PDF_LIBRARY = None

try:
    import pdfplumber
    PDF_AVAILABLE = True
    PDF_LIBRARY = "pdfplumber"
except ImportError:
    st.warning("PDF processing not available. Install: pip install pdfplumber")

# Load FAQ data
@st.cache_data
def load_faq_data():
    try:
        with open('college_faq.json', 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        st.error("college_faq.json not found. Please ensure the file exists.")
        return []

faq_data = load_faq_data()

# Page config
st.set_page_config(
    page_title="College Admission Chatbot",
    page_icon="ğŸ“",
    layout="wide"
)

# CSS Styling
st.markdown("""
<style>
.main-header {
    background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
    padding: 2rem;
    border-radius: 15px;
    color: white;
    text-align: center;
    margin-bottom: 2rem;
    box-shadow: 0 10px 30px rgba(102, 126, 234, 0.3);
}

.chat-container {
    background: #f8f9fa;
    padding: 1.5rem;
    border-radius: 15px;
    margin: 1rem 0;
    border: 1px solid #e9ecef;
}

.answer-box {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    padding: 1.5rem;
    border-radius: 15px;
    margin: 1rem 0;
    box-shadow: 0 8px 32px rgba(102, 126, 234, 0.3);
}

.sidebar-section {
    background: #f8f9fa;
    padding: 1rem;
    border-radius: 10px;
    margin: 1rem 0;
    border-left: 4px solid #667eea;
}

.notification-detail {
    background: #e7f3ff;
    padding: 1rem;
    border-radius: 10px;
    margin: 1rem 0;
    border-left: 4px solid #0dcaf0;
}

@keyframes bounce {
    0%, 20%, 50%, 80%, 100% { transform: translateY(0); }
    40% { transform: translateY(-10px); }
    60% { transform: translateY(-5px); }
}

@keyframes pulse {
    0% { transform: scale(1); }
    50% { transform: scale(1.05); }
    100% { transform: scale(1); }
}
</style>
""", unsafe_allow_html=True)

# Language selection
language = st.selectbox("ğŸŒ Language / à¤­à¤¾à¤·à¤¾ / à®®à¯Šà®´à®¿", ["English", "Hindi", "Tamil"], key="language_select")

# Translations
# Translations
translations = {
    "English": {
        "title": "ğŸ“ College Admission Chatbot",
        "subtitle": "Ask any question about admissions, courses, fees, dates, and more!",
        "input_placeholder": "e.g., What is the eligibility for B.Tech?",
        "detected_intent": "ğŸ¯ Detected Intent:",
        "answer": "ğŸ¤– Answer:",
        "conversation_history": "ğŸ’¬ Conversation History",
        "quick_questions": "ğŸ¯ Quick Questions",
        "quick_questions_list": [
            "What is the eligibility for B.Tech?",
            "What are the fees for MBA?",
            "What is the last date to apply?",
            "How much is the hostel fee?",
            "What is the counseling process?"
        ],
        "latest_updates": "ğŸ“¢ Latest Updates",
        "notifications": [
            "ğŸš¨ Last Week for Applications",
            "ğŸ“ New Scholarship Program",
            "ğŸ“… Exam Dates Announced"
        ],
        "notification_details": [
            "Only 7 days left to submit your application for the August batch!",
            "Merit-based scholarships up to 75% now available. Apply before March 20th!",
            "Entrance exam dates have been announced. Check your email for details."
        ],
        "upload_resume": "ğŸ“„ Upload Resume",
        "upload_file": "Choose file",
        "get_suggestions": "Get Course Suggestions",
        "recommended_courses": "Recommended Courses:",
        "upload_detailed": "Upload a more detailed resume for better suggestions.",
        "contact_support": "ğŸ“ **Need Help?** Contact: admissions@college.edu | +91-1234567890"
    },
    "Hindi": {
        "title": "ğŸ“ à¤•à¥‰à¤²à¥‡à¤œ à¤ªà¥à¤°à¤µà¥‡à¤¶ à¤šà¥ˆà¤Ÿà¤¬à¥‰à¤Ÿ",
        "subtitle": "à¤ªà¥à¤°à¤µà¥‡à¤¶, à¤•à¥‹à¤°à¥à¤¸, à¤«à¥€à¤¸, à¤¤à¤¾à¤°à¥€à¤–à¥‹à¤‚ à¤•à¥‡ à¤¬à¤¾à¤°à¥‡ à¤®à¥‡à¤‚ à¤•à¥‹à¤ˆ à¤­à¥€ à¤ªà¥à¤°à¤¶à¥à¤¨ à¤ªà¥‚à¤›à¥‡à¤‚!",
        "input_placeholder": "à¤œà¥ˆà¤¸à¥‡, B.Tech à¤•à¥‡ à¤²à¤¿à¤ à¤¯à¥‹à¤—à¥à¤¯à¤¤à¤¾ à¤•à¥à¤¯à¤¾ à¤¹à¥ˆ?",
        "detected_intent": "ğŸ¯ à¤ªà¤¹à¤šà¤¾à¤¨à¤¾ à¤—à¤¯à¤¾ à¤‡à¤°à¤¾à¤¦à¤¾:",
        "answer": "ğŸ¤– à¤‰à¤¤à¥à¤¤à¤°:",
        "conversation_history": "ğŸ’¬ à¤¬à¤¾à¤¤à¤šà¥€à¤¤ à¤•à¤¾ à¤‡à¤¤à¤¿à¤¹à¤¾à¤¸",
        "quick_questions": "ğŸ¯ à¤¤à¥à¤µà¤°à¤¿à¤¤ à¤ªà¥à¤°à¤¶à¥à¤¨",
        "quick_questions_list": [
            "B.Tech à¤•à¥‡ à¤²à¤¿à¤ à¤¯à¥‹à¤—à¥à¤¯à¤¤à¤¾ à¤•à¥à¤¯à¤¾ à¤¹à¥ˆ?",
            "MBA à¤•à¥€ à¤«à¥€à¤¸ à¤•à¥à¤¯à¤¾ à¤¹à¥ˆ?",
            "à¤†à¤µà¥‡à¤¦à¤¨ à¤•à¥€ à¤…à¤‚à¤¤à¤¿à¤® à¤¤à¤¾à¤°à¥€à¤– à¤•à¥à¤¯à¤¾ à¤¹à¥ˆ?",
            "à¤¹à¥‰à¤¸à¥à¤Ÿà¤² à¤•à¥€ à¤«à¥€à¤¸ à¤•à¤¿à¤¤à¤¨à¥€ à¤¹à¥ˆ?",
            "à¤•à¤¾à¤‰à¤‚à¤¸à¤²à¤¿à¤‚à¤— à¤ªà¥à¤°à¤•à¥à¤°à¤¿à¤¯à¤¾ à¤•à¥à¤¯à¤¾ à¤¹à¥ˆ?"
        ],
        "latest_updates": "ğŸ“¢ à¤¨à¤µà¥€à¤¨à¤¤à¤® à¤…à¤ªà¤¡à¥‡à¤Ÿ",
        "notifications": [
            "ğŸš¨ à¤†à¤µà¥‡à¤¦à¤¨ à¤•à¥‡ à¤²à¤¿à¤ à¤…à¤‚à¤¤à¤¿à¤® à¤¸à¤ªà¥à¤¤à¤¾à¤¹",
            "ğŸ“ à¤¨à¤¯à¤¾ à¤›à¤¾à¤¤à¥à¤°à¤µà¥ƒà¤¤à¥à¤¤à¤¿ à¤•à¤¾à¤°à¥à¤¯à¤•à¥à¤°à¤®",
            "ğŸ“… à¤ªà¤°à¥€à¤•à¥à¤·à¤¾ à¤¤à¤¿à¤¥à¤¿à¤¯à¤¾à¤‚ à¤˜à¥‹à¤·à¤¿à¤¤"
        ],
        "notification_details": [
            "à¤…à¤—à¤¸à¥à¤¤ à¤¬à¥ˆà¤š à¤•à¥‡ à¤²à¤¿à¤ à¤†à¤µà¥‡à¤¦à¤¨ à¤œà¤®à¤¾ à¤•à¤°à¤¨à¥‡ à¤•à¥‡ à¤²à¤¿à¤ à¤•à¥‡à¤µà¤² 7 à¤¦à¤¿à¤¨ à¤¬à¤šà¥‡ à¤¹à¥ˆà¤‚!",
            "75% à¤¤à¤• à¤®à¥‡à¤§à¤¾ à¤†à¤§à¤¾à¤°à¤¿à¤¤ à¤›à¤¾à¤¤à¥à¤°à¤µà¥ƒà¤¤à¥à¤¤à¤¿ à¤‰à¤ªà¤²à¤¬à¥à¤§à¥¤ 20 à¤®à¤¾à¤°à¥à¤š à¤¸à¥‡ à¤ªà¤¹à¤²à¥‡ à¤†à¤µà¥‡à¤¦à¤¨ à¤•à¤°à¥‡à¤‚!",
            "à¤ªà¥à¤°à¤µà¥‡à¤¶ à¤ªà¤°à¥€à¤•à¥à¤·à¤¾ à¤•à¥€ à¤¤à¤¾à¤°à¥€à¤–à¥‡à¤‚ à¤˜à¥‹à¤·à¤¿à¤¤ à¤•à¥€ à¤—à¤ˆ à¤¹à¥ˆà¤‚à¥¤ à¤µà¤¿à¤µà¤°à¤£ à¤•à¥‡ à¤²à¤¿à¤ à¤…à¤ªà¤¨à¤¾ à¤ˆà¤®à¥‡à¤² à¤šà¥‡à¤• à¤•à¤°à¥‡à¤‚à¥¤"
        ],
        "upload_resume": "ğŸ“„ à¤°à¤¿à¤œà¥à¤¯à¥‚à¤®à¥‡ à¤…à¤ªà¤²à¥‹à¤¡ à¤•à¤°à¥‡à¤‚",
        "upload_file": "à¤«à¤¾à¤‡à¤² à¤šà¥à¤¨à¥‡à¤‚",
        "get_suggestions": "à¤•à¥‹à¤°à¥à¤¸ à¤¸à¥à¤à¤¾à¤µ à¤ªà¥à¤°à¤¾à¤ªà¥à¤¤ à¤•à¤°à¥‡à¤‚",
        "recommended_courses": "à¤…à¤¨à¥à¤¶à¤‚à¤¸à¤¿à¤¤ à¤•à¥‹à¤°à¥à¤¸:",
        "upload_detailed": "à¤¬à¥‡à¤¹à¤¤à¤° à¤¸à¥à¤à¤¾à¤µà¥‹à¤‚ à¤•à¥‡ à¤²à¤¿à¤ à¤…à¤§à¤¿à¤• à¤µà¤¿à¤¸à¥à¤¤à¥ƒà¤¤ à¤°à¤¿à¤œà¥à¤¯à¥‚à¤®à¥‡ à¤…à¤ªà¤²à¥‹à¤¡ à¤•à¤°à¥‡à¤‚à¥¤",
        "contact_support": "ğŸ“ **à¤¸à¤¹à¤¾à¤¯à¤¤à¤¾ à¤šà¤¾à¤¹à¤¿à¤?** à¤¸à¤‚à¤ªà¤°à¥à¤•: admissions@college.edu | +91-1234567890"
    },
    "Tamil": {
        "title": "ğŸ“ à®•à®²à¯à®²à¯‚à®°à®¿ à®šà¯‡à®°à¯à®•à¯à®•à¯ˆ à®šà®¾à®Ÿà¯à®ªà¯‹à®Ÿà¯",
        "subtitle": "à®šà¯‡à®°à¯à®•à¯à®•à¯ˆ, à®ªà®Ÿà®¿à®ªà¯à®ªà¯à®•à®³à¯, à®•à®Ÿà¯à®Ÿà®£à®®à¯, à®¤à¯‡à®¤à®¿à®•à®³à¯ à®ªà®±à¯à®±à®¿ à®à®¨à¯à®¤ à®•à¯‡à®³à¯à®µà®¿à®¯à¯à®®à¯ à®•à¯‡à®³à¯à®™à¯à®•à®³à¯!",
        "input_placeholder": "à®‰à®¤à®¾à®°à®£à®®à¯, B.Tech-à®•à¯à®•à®¾à®© à®¤à®•à¯à®¤à®¿ à®à®©à¯à®©?",
        "detected_intent": "ğŸ¯ à®•à®£à¯à®Ÿà®±à®¿à®¯à®ªà¯à®ªà®Ÿà¯à®Ÿ à®¨à¯‹à®•à¯à®•à®®à¯:",
        "answer": "ğŸ¤– à®ªà®¤à®¿à®²à¯:",
        "conversation_history": "ğŸ’¬ à®‰à®°à¯ˆà®¯à®¾à®Ÿà®²à¯ à®µà®°à®²à®¾à®±à¯",
        "quick_questions": "ğŸ¯ à®µà®¿à®°à¯ˆà®µà¯ à®•à¯‡à®³à¯à®µà®¿à®•à®³à¯",
        "quick_questions_list": [
            "B.Tech-à®•à¯à®•à®¾à®© à®¤à®•à¯à®¤à®¿ à®à®©à¯à®©?",
            "MBA à®•à®Ÿà¯à®Ÿà®£à®®à¯ à®à®©à¯à®©?",
            "à®µà®¿à®£à¯à®£à®ªà¯à®ªà®¿à®•à¯à®• à®•à®Ÿà¯ˆà®šà®¿ à®¤à¯‡à®¤à®¿ à®à®©à¯à®©?",
            "à®µà®¿à®Ÿà¯à®¤à®¿ à®•à®Ÿà¯à®Ÿà®£à®®à¯ à®à®µà¯à®µà®³à®µà¯?",
            "à®†à®²à¯‹à®šà®©à¯ˆ à®šà¯†à®¯à®²à¯à®®à¯à®±à¯ˆ à®à®©à¯à®©?"
        ],
        "latest_updates": "ğŸ“¢ à®šà®®à¯€à®ªà®¤à¯à®¤à®¿à®¯ à®ªà¯à®¤à¯à®ªà¯à®ªà®¿à®ªà¯à®ªà¯à®•à®³à¯",
        "notifications": [
            "ğŸš¨ à®µà®¿à®£à¯à®£à®ªà¯à®ªà®™à¯à®•à®³à¯à®•à¯à®•à®¾à®© à®•à®Ÿà¯ˆà®šà®¿ à®µà®¾à®°à®®à¯",
            "ğŸ“ à®ªà¯à®¤à®¿à®¯ à®‰scholarship à®¤à®¿à®Ÿà¯à®Ÿà®®à¯",
            "ğŸ“… à®¤à¯‡à®°à¯à®µà¯ à®¤à¯‡à®¤à®¿à®•à®³à¯ à®…à®±à®¿à®µà®¿à®•à¯à®•à®ªà¯à®ªà®Ÿà¯à®Ÿà®©"
        ],
        "notification_details": [
            "à®†à®•à®¸à¯à®Ÿà¯ batch-à®•à¯à®•à¯ à®µà®¿à®£à¯à®£à®ªà¯à®ªà®®à¯ à®šà®®à®°à¯à®ªà¯à®ªà®¿à®•à¯à®• 7 à®¨à®¾à®Ÿà¯à®•à®³à¯ à®®à®Ÿà¯à®Ÿà¯à®®à¯‡ à®‰à®³à¯à®³à®©!",
            "75% à®µà®°à¯ˆ merit à®…à®Ÿà®¿à®ªà¯à®ªà®Ÿà¯ˆà®¯à®¿à®²à®¾à®© à®‰à®¤à®µà®¿à®¤à¯à®¤à¯Šà®•à¯ˆ à®•à®¿à®Ÿà¯ˆà®•à¯à®•à®¿à®±à®¤à¯. à®®à®¾à®°à¯à®šà¯ 20-à®•à¯à®•à¯ à®®à¯à®©à¯ à®µà®¿à®£à¯à®£à®ªà¯à®ªà®¿à®•à¯à®•à®µà¯à®®à¯!",
            "à®¨à¯à®´à¯ˆà®µà¯à®¤à¯ à®¤à¯‡à®°à¯à®µà¯ à®¤à¯‡à®¤à®¿à®•à®³à¯ à®…à®±à®¿à®µà®¿à®•à¯à®•à®ªà¯à®ªà®Ÿà¯à®Ÿà¯à®³à¯à®³à®©. à®µà®¿à®µà®°à®™à¯à®•à®³à¯à®•à¯à®•à¯ à®‰à®™à¯à®•à®³à¯ à®®à®¿à®©à¯à®©à®à¯à®šà®²à¯ˆà®šà¯ à®šà®°à®¿à®ªà®¾à®°à¯à®•à¯à®•à®µà¯à®®à¯."
        ],
        "upload_resume": "ğŸ“„ Resume à®ªà®¤à®¿à®µà¯‡à®±à¯à®±à®µà¯à®®à¯",
        "upload_file": "à®•à¯‹à®ªà¯à®ªà¯ˆà®¤à¯ à®¤à¯‡à®°à¯à®¨à¯à®¤à¯†à®Ÿà¯à®•à¯à®•à®µà¯à®®à¯",
        "get_suggestions": "à®ªà®Ÿà®¿à®ªà¯à®ªà¯ à®ªà®°à®¿à®¨à¯à®¤à¯à®°à¯ˆà®•à®³à¯ˆà®ªà¯ à®ªà¯†à®±à®µà¯à®®à¯",
        "recommended_courses": "à®ªà®°à®¿à®¨à¯à®¤à¯à®°à¯ˆà®•à¯à®•à®ªà¯à®ªà®Ÿà¯à®Ÿ à®ªà®Ÿà®¿à®ªà¯à®ªà¯à®•à®³à¯:",
        "upload_detailed": "à®šà®¿à®±à®¨à¯à®¤ à®ªà®°à®¿à®¨à¯à®¤à¯à®°à¯ˆà®•à®³à¯à®•à¯à®•à¯ à®®à®¿à®•à®µà¯à®®à¯ à®µà®¿à®°à®¿à®µà®¾à®© resume à®ªà®¤à®¿à®µà¯‡à®±à¯à®±à®µà¯à®®à¯à¥¤",
        "contact_support": "ğŸ“ **à®‰à®¤à®µà®¿ à®¤à¯‡à®µà¯ˆà®¯à®¾?** à®¤à¯Šà®Ÿà®°à¯à®ªà¯: admissions@college.edu | +91-1234567890"
    }
}
t = translations[language]

# Initialize session state
if 'conversation_history' not in st.session_state:
    st.session_state.conversation_history = []
if 'selected_notification' not in st.session_state:
    st.session_state.selected_notification = None
if 'analytics' not in st.session_state:
    st.session_state.analytics = {
        'questions_asked': 0,
        'languages_used': {},
        'intents_detected': {},
        'user_ratings': [],
        'session_start': datetime.now(),
        'response_times': [],
        'satisfaction_scores': []
    }
if 'user_preferences' not in st.session_state:
    st.session_state.user_preferences = {
        'show_confidence': True,
        'typing_animation': True,
        'auto_suggestions': True
    }
if 'show_analytics' not in st.session_state:
    st.session_state.show_analytics = False

# Header
st.markdown(f'<div class="main-header"><h1>{t["title"]}</h1><p style="margin-top: 1rem; font-size: 1.1rem; opacity: 0.9;">{t["subtitle"]}</p></div>', unsafe_allow_html=True)

# Load model
@st.cache_resource
def load_model():
    if TRANSFORMERS_AVAILABLE:
        try:
            return pipeline("text2text-generation", model="google/flan-t5-small", local_files_only=True)
        except Exception as e:
            st.warning(f"Offline model not available. Using rule-based responses. Error: {e}")
            return None
    return None

qa_pipeline = load_model() if TRANSFORMERS_AVAILABLE else None

if not TRANSFORMERS_AVAILABLE or qa_pipeline is None:
    st.info("ğŸ”„ Running in offline mode with rule-based responses. All basic features are available!")
else:
    st.success("ğŸ¤– AI model loaded successfully!")

# PDF processing function
def extract_text_from_pdf(pdf_file):
    if not PDF_AVAILABLE:
        st.error("PDF processing not available. Please upload a TXT file instead.")
        return ""
    
    try:
        if PDF_LIBRARY == "pdfplumber":
            with pdfplumber.open(io.BytesIO(pdf_file.read())) as pdf:
                text = ""
                for page in pdf.pages:
                    text += page.extract_text() or ""
                return text
    except Exception as e:
        st.error(f"Error reading PDF: {str(e)}")
        return ""

# Enhanced answer function with confidence scoring
def get_answer_with_confidence(question):
    start_time = time.time()
    question_lower = question.lower().strip()
    confidence = 0.0
    
    # First, try exact match from JSON data
    for item in faq_data:
        if question_lower == item['prompt'].lower().strip():
            response_time = time.time() - start_time
            return item['response'], 1.0, response_time
    
    # Enhanced keyword matching for better responses
    best_match = None
    max_score = 0
    
    for item in faq_data:
        prompt_lower = item['prompt'].lower()
        score = 0
        
        # Count matching words
        question_words = set(question_lower.split())
        prompt_words = set(prompt_lower.split())
        common_words = question_words.intersection(prompt_words)
        
        if common_words:
            score = len(common_words) / len(question_words.union(prompt_words))
            
        # Boost score for key terms
        if 'scholarship' in question_lower and 'scholarship' in prompt_lower:
            score += 0.5
        if 'fee' in question_lower and 'fee' in prompt_lower:
            score += 0.3
            
        if score > max_score and score > 0.2:
            max_score = score
            best_match = item['response']
            confidence = score
    
    if best_match:
        response_time = time.time() - start_time
        return best_match, confidence, response_time
    
    # Specific fallback for scholarship questions
    if 'scholarship' in question_lower:
        response_time = time.time() - start_time
        return "Scholarships are available for meritorious and economically weaker students. Please check the scholarship section on our website for detailed information and application procedures.", 0.7, response_time
    
    # General fallback response
    response_time = time.time() - start_time
    fallback_answer = "I'm sorry, I don't have specific information about that. Please contact our admissions office at admissions@college.edu or call +91-1234567890 for detailed assistance."
    return fallback_answer, 0.3, response_time

# Keep original get_answer for backward compatibility
def get_answer(question):
    answer, confidence, response_time = get_answer_with_confidence(question)
    return answer

def classify_intent(question):
    question_lower = question.lower()
    
    # Check if question exists in FAQ data
    for item in faq_data:
        if question_lower in item['prompt'].lower() or item['prompt'].lower() in question_lower:
            # Classify based on content
            prompt_lower = item['prompt'].lower()
            if any(word in prompt_lower for word in ['fee', 'cost', 'payment', 'money']):
                return 'fees'
            elif any(word in prompt_lower for word in ['date', 'deadline', 'when', 'time']):
                return 'dates'
            elif any(word in prompt_lower for word in ['eligibility', 'criteria', 'requirement']):
                return 'eligibility'
            elif any(word in prompt_lower for word in ['course', 'program', 'degree']):
                return 'courses'
            elif any(word in prompt_lower for word in ['admission', 'apply', 'process']):
                return 'admission'
    
    # Fallback to original classification
    intents = {
        'fees': ['fee', 'cost', 'payment', 'money', 'scholarship'],
        'dates': ['date', 'deadline', 'when', 'time', 'exam', 'result'],
        'eligibility': ['eligibility', 'criteria', 'requirement', 'qualify'],
        'courses': ['course', 'program', 'degree', 'branch', 'subject'],
        'admission': ['admission', 'apply', 'process', 'form'],
        'hostel': ['hostel', 'accommodation', 'room'],
        'placement': ['placement', 'job', 'career', 'company']
    }
    
    for intent, keywords in intents.items():
        if any(word in question_lower for word in keywords):
            return intent
    return 'general'

# Enhanced chat interface
st.markdown('<div class="chat-container">', unsafe_allow_html=True)

# Interactive input row
col1, col2, col3, col4 = st.columns([6, 1, 1, 1])
with col1:
    user_input = st.text_input("ğŸ’¬", placeholder=t["input_placeholder"], label_visibility="collapsed", key="main_input")
with col2:
    if st.button("ğŸ¤", help="Voice Input (Coming Soon)", key="voice_btn"):
        st.info("ğŸ¤ Voice input feature coming soon!")
with col3:
    if st.button("ğŸ”", help="Search Chat", key="search_btn"):
        st.session_state.show_search = not st.session_state.get('show_search', False)
with col4:
    if st.button("ğŸ“Š", help="Analytics", key="analytics_btn"):
        st.session_state.show_analytics = not st.session_state.get('show_analytics', False)

# Search functionality
if st.session_state.get('show_search', False):
    search_term = st.text_input("ğŸ” Search conversations:", key="search_input")
    if search_term and st.session_state.conversation_history:
        st.write("**Search Results:**")
        for i, qa in enumerate(st.session_state.conversation_history):
            if search_term.lower() in qa['question'].lower() or search_term.lower() in qa['answer'].lower():
                st.write(f"**Q:** {qa['question']}")
                st.write(f"**A:** {qa['answer'][:100]}...")
                st.write("---")

# Analytics dashboard
if st.session_state.get('show_analytics', False):
    st.markdown("### ğŸ“Š Session Analytics")
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Questions Asked", st.session_state.analytics['questions_asked'])
    with col2:
        avg_rating = sum(st.session_state.analytics['user_ratings']) / len(st.session_state.analytics['user_ratings']) if st.session_state.analytics['user_ratings'] else 0
        st.metric("Avg Rating", f"{avg_rating:.1f}â­")
    with col3:
        session_duration = (datetime.now() - st.session_state.analytics['session_start']).seconds // 60
        st.metric("Session Duration", f"{session_duration} min")
    with col4:
        avg_response_time = sum(st.session_state.analytics['response_times']) / len(st.session_state.analytics['response_times']) if st.session_state.analytics['response_times'] else 0
        st.metric("Avg Response Time", f"{avg_response_time:.2f}s")
    
    # Intent distribution chart
    if PLOTLY_AVAILABLE and st.session_state.analytics['intents_detected']:
        try:
            intent_df = pd.DataFrame(list(st.session_state.analytics['intents_detected'].items()), 
                                    columns=['Intent', 'Count'])
            fig = px.pie(intent_df, values='Count', names='Intent', title='Question Categories')
            st.plotly_chart(fig, use_container_width=True)
        except Exception as e:
            st.error(f"Chart error: {e}")
    
    # Language usage chart
    if PLOTLY_AVAILABLE and st.session_state.analytics['languages_used']:
        try:
            lang_df = pd.DataFrame(list(st.session_state.analytics['languages_used'].items()), 
                                  columns=['Language', 'Count'])
            fig_lang = px.bar(lang_df, x='Language', y='Count', title='Language Usage')
            st.plotly_chart(fig_lang, use_container_width=True)
        except Exception as e:
            st.error(f"Language chart error: {e}")
    
    # Response time trend
    if st.session_state.analytics['response_times']:
        try:
            response_times = st.session_state.analytics['response_times'][-20:]  # Last 20 responses
            fig_time = px.line(x=range(len(response_times)), y=response_times, 
                              title='Response Time Trend', 
                              labels={'x': 'Question Number', 'y': 'Response Time (s)'})
            st.plotly_chart(fig_time, use_container_width=True)
        except Exception as e:
            st.error(f"Response time chart error: {e}")
    
    # Hide analytics button
    if st.button("âŒ Hide Analytics", key="hide_analytics"):
        st.session_state.show_analytics = False
        st.rerun()

# Main chat processing
if user_input:
    # Show typing indicator
    with st.spinner("ğŸ¤” Thinking..."):
        time.sleep(0.5)  # Simulate processing time
        
    intent = classify_intent(user_input)
    answer, confidence, response_time = get_answer_with_confidence(user_input)
    
    # Display intent
    st.info(f"ğŸ¯ {t['detected_intent']} **{intent.title()}**")
    
    # Display answer with Streamlit components
    st.markdown("### ğŸ¤– Answer:")
    
    # Answer in a nice container
    with st.container():
        st.markdown(f"""
        <div style="
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 1.5rem;
            border-radius: 15px;
            margin: 1rem 0;
        ">
            <div style="font-size: 1.1rem; line-height: 1.6;">
                {answer}
            </div>
        </div>
        """, unsafe_allow_html=True)
    
    # Metrics in columns
    col1, col2, col3 = st.columns(3)
    with col1:
        confidence_emoji = "ğŸŸ¢" if confidence > 0.7 else "ğŸŸ¡" if confidence > 0.5 else "ğŸ”´"
        st.metric("Confidence", f"{confidence:.0%}", delta=confidence_emoji)
    with col2:
        st.metric("Response Time", f"{response_time:.2f}s")
    with col3:
        st.metric("Category", intent.title())
    
    # Rating system - Enhanced UI with gradients and colors
    st.markdown("**â­ Rate this response:**")
    
    # Add custom CSS for rating buttons
    st.markdown("""
    <style>
    .rating-button {
        background: linear-gradient(45deg, #ff9a9e 0%, #fecfef 50%, #fecfef 100%);
        border: none;
        border-radius: 15px;
        padding: 0.5rem 1rem;
        color: white;
        font-weight: bold;
        text-shadow: 1px 1px 2px rgba(0,0,0,0.3);
        box-shadow: 0 4px 15px rgba(255, 154, 158, 0.4);
        transition: all 0.3s ease;
        cursor: pointer;
    }
    
    .rating-button:hover {
        transform: translateY(-2px);
        box-shadow: 0 6px 20px rgba(255, 154, 158, 0.6);
        background: linear-gradient(45deg, #ff6b6b 0%, #ff8e8e 50%, #ffb3b3 100%);
    }
    
    .rating-button-1 {
        background: linear-gradient(45deg, #ff6b6b 0%, #ee5a52 100%);
        box-shadow: 0 4px 15px rgba(255, 107, 107, 0.4);
    }
    
    .rating-button-2 {
        background: linear-gradient(45deg, #ffa726 0%, #ff9800 100%);
        box-shadow: 0 4px 15px rgba(255, 167, 38, 0.4);
    }
    
    .rating-button-3 {
        background: linear-gradient(45deg, #ffeb3b 0%, #ffc107 100%);
        box-shadow: 0 4px 15px rgba(255, 235, 59, 0.4);
    }
    
    .rating-button-4 {
        background: linear-gradient(45deg, #8bc34a 0%, #4caf50 100%);
        box-shadow: 0 4px 15px rgba(139, 195, 74, 0.4);
    }
    
    .rating-button-5 {
        background: linear-gradient(45deg, #4caf50 0%, #2e7d32 100%);
        box-shadow: 0 4px 15px rgba(76, 175, 80, 0.4);
        animation: pulse 2s infinite;
    }
    
    @keyframes pulse {
        0% { transform: scale(1); }
        50% { transform: scale(1.05); }
        100% { transform: scale(1); }
    }
    
    .rating-container {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1.5rem;
        border-radius: 20px;
        margin: 1rem 0;
        box-shadow: 0 10px 30px rgba(102, 126, 234, 0.3);
    }
    
    .rating-title {
        color: white;
        font-size: 1.2rem;
        font-weight: bold;
        text-align: center;
        margin-bottom: 1rem;
        text-shadow: 1px 1px 2px rgba(0,0,0,0.3);
    }
    </style>
    """, unsafe_allow_html=True)
    
    # Create rating container with gradient background
    st.markdown('<div class="rating-container">', unsafe_allow_html=True)
    st.markdown('<div class="rating-title">â­ Rate this response:</div>', unsafe_allow_html=True)
    
    # Create unique key for this response
    current_question = user_input
    rating_key = f"rating_{hash(current_question)}_{len(st.session_state.conversation_history)}"
    
    # Initialize rating in session state if not exists
    if rating_key not in st.session_state:
        st.session_state[rating_key] = 0
    
    # Create 5 rating buttons in columns with custom styling
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        if st.button("â­", key=f"btn1_{rating_key}", use_container_width=True, type="secondary"):
            st.session_state[rating_key] = 1
    
    with col2:
        if st.button("â­â­", key=f"btn2_{rating_key}", use_container_width=True, type="secondary"):
            st.session_state[rating_key] = 2
    
    with col3:
        if st.button("â­â­â­", key=f"btn3_{rating_key}", use_container_width=True, type="secondary"):
            st.session_state[rating_key] = 3
    
    with col4:
        if st.button("â­â­â­â­", key=f"btn4_{rating_key}", use_container_width=True, type="secondary"):
            st.session_state[rating_key] = 4
    
    with col5:
        if st.button("â­â­â­â­â­", key=f"btn5_{rating_key}", use_container_width=True, type="primary"):
            st.session_state[rating_key] = 5
    
    st.markdown('</div>', unsafe_allow_html=True)
    
    # Get current rating from session state
    current_rating = st.session_state[rating_key]
    
    # Show feedback if rating was given
    if current_rating > 0:
        st.balloons()
        st.success(f"ğŸ‰ You rated: {current_rating} star{'s' if current_rating > 1 else ''}!")
        
        # Enhanced feedback with animated gradient
        descriptions = {1: "Poor", 2: "Fair", 3: "Good", 4: "Very Good", 5: "Excellent"}
        colors = {
            1: "linear-gradient(135deg, #ff6b6b 0%, #ee5a52 100%)",
            2: "linear-gradient(135deg, #ffa726 0%, #ff9800 100%)", 
            3: "linear-gradient(135deg, #ffeb3b 0%, #ffc107 100%)",
            4: "linear-gradient(135deg, #8bc34a 0%, #4caf50 100%)",
            5: "linear-gradient(135deg, #4caf50 0%, #2e7d32 100%)"
        }
        
        # Add bounce animation CSS first
        st.markdown("""
        <style>
        @keyframes bounce {
            0%, 20%, 50%, 80%, 100% { transform: scale(1.02) translateY(0); }
            40% { transform: scale(1.02) translateY(-10px); }
            60% { transform: scale(1.02) translateY(-5px); }
        }
        </style>
        """, unsafe_allow_html=True)
        
        # Then add the feedback box
        feedback_html = f"""
        <div style="
            background: {colors[current_rating]};
            color: white;
            padding: 2rem;
            border-radius: 20px;
            text-align: center;
            margin: 1rem 0;
            box-shadow: 0 15px 40px rgba(0,0,0,0.2);
            transform: scale(1.02);
            animation: bounce 0.6s ease-in-out;
        ">
            <h2 style="margin: 0; font-size: 1.5rem;">ğŸ‰ Thank you for your feedback!</h2>
            <div style="font-size: 3rem; margin: 1rem 0; text-shadow: 2px 2px 4px rgba(0,0,0,0.3);">
                {'â­' * current_rating}
            </div>
            <h3 style="margin: 0; font-size: 1.3rem;">
                You rated: <strong>{descriptions[current_rating]}</strong>
            </h3>
            <p style="font-size: 1rem; opacity: 0.9; margin-top: 0.5rem;">
                Your feedback helps us improve! ğŸš€
            </p>
        </div>
        """
        
        st.markdown(feedback_html, unsafe_allow_html=True)
        
        # Contextual message with matching colors
        if current_rating >= 4:
            st.success("ğŸ¯ Awesome! We're thrilled you found our response helpful!")
        elif current_rating == 3:
            st.info("ğŸ‘ Thank you! We're always working to improve.")
        else:
            st.warning("ğŸ“ Thanks for the feedback! We'll work harder to help you better.")
        
        # Add to analytics only once
        if current_rating not in st.session_state.analytics['user_ratings']:
            st.session_state.analytics['user_ratings'].append(current_rating)
    
    # Update analytics
    st.session_state.analytics['questions_asked'] += 1
    st.session_state.analytics['languages_used'][language] = st.session_state.analytics['languages_used'].get(language, 0) + 1
    st.session_state.analytics['intents_detected'][intent] = st.session_state.analytics['intents_detected'].get(intent, 0) + 1
    st.session_state.analytics['response_times'].append(response_time)
    
    # Save conversation with current rating (will be 0 initially, updated when user rates)
    conversation_entry = {
        'question': user_input,
        'answer': answer,
        'intent': intent,
        'confidence': confidence,
        'response_time': response_time,
        'rating': current_rating,
        'timestamp': datetime.now().isoformat()
    }
    
    # Check if this conversation already exists, if so update it
    existing_index = None
    for i, conv in enumerate(st.session_state.conversation_history):
        if conv['question'] == user_input and conv['answer'] == answer:
            existing_index = i
            break
    
    if existing_index is not None:
        st.session_state.conversation_history[existing_index] = conversation_entry
    else:
        st.session_state.conversation_history.append(conversation_entry)

st.markdown('</div>', unsafe_allow_html=True)

    
# Conversation History
if st.session_state.conversation_history:
    st.markdown(f'<div class="sidebar-section"><h3>{t["conversation_history"]}</h3></div>', unsafe_allow_html=True)
    
    # Search and filter options
    col1, col2 = st.columns(2)
    with col1:
        history_search = st.text_input("ğŸ” Search history:", key="history_search")
    with col2:
        intent_options = ["All"] + list(set([qa.get('intent', 'Unknown') for qa in st.session_state.conversation_history]))
        intent_filter = st.selectbox("Filter by category:", intent_options, key="intent_filter")
    
    # Filter conversations
    filtered_history = st.session_state.conversation_history
    if history_search:
        filtered_history = [qa for qa in filtered_history 
                          if history_search.lower() in qa['question'].lower() or history_search.lower() in qa['answer'].lower()]
    if intent_filter != "All":
        filtered_history = [qa for qa in filtered_history if qa.get('intent') == intent_filter]
    
    # Display conversations
    for i, qa in enumerate(reversed(filtered_history[-5:]), 1):
        confidence = qa.get('confidence', 0)
        confidence_emoji = "ğŸŸ¢" if confidence > 0.7 else "ğŸŸ¡" if confidence > 0.5 else "ğŸ”´"
        rating_display = "â­" * qa.get('rating', 0) if qa.get('rating') else "âšª No rating"
        
        with st.expander(f"{confidence_emoji} Q{len(filtered_history)-i+1}: {qa['question'][:50]}... | {rating_display}"):
            st.markdown(f"**ğŸ‘¤ Question:** {qa['question']}")
            st.markdown(f"**ğŸ¤– Answer:** {qa['answer']}")
            
            # Metadata
            meta_col1, meta_col2, meta_col3, meta_col4 = st.columns(4)
            with meta_col1:
                st.write(f"**ğŸ“‚ Category:** {qa.get('intent', 'Unknown').title()}")
            with meta_col2:
                st.write(f"**ğŸ¯ Confidence:** {confidence:.0%}")
            with meta_col3:
                st.write(f"**â±ï¸ Response:** {qa.get('response_time', 0):.2f}s")
            with meta_col4:
                timestamp = qa.get('timestamp', '')
                if timestamp:
                    time_str = timestamp[:16].replace('T', ' ')
                    st.write(f"**ğŸ• Time:** {time_str}")

# Sidebar features
st.sidebar.markdown(f'<div class="sidebar-section"><h3>{t["quick_questions"]}</h3></div>', unsafe_allow_html=True)

for q in t["quick_questions_list"]:
    if st.sidebar.button(q, key=f"quick_{hash(q)}"):
        st.session_state.temp_question = q

# Handle quick question clicks
if hasattr(st.session_state, 'temp_question'):
    intent = classify_intent(st.session_state.temp_question)
    answer, confidence, response_time = get_answer_with_confidence(st.session_state.temp_question)
    
    # Display intent
    st.info(f"ğŸ¯ {t['detected_intent']} **{intent.title()}**")
    
    # Display answer
    st.markdown("### ğŸ¤– Answer:")
    with st.container():
        st.markdown(f"""
        <div style="
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 1.5rem;
            border-radius: 15px;
            margin: 1rem 0;
        ">
            <div style="font-size: 1.1rem; line-height: 1.6;">
                {answer}
            </div>
        </div>
        """, unsafe_allow_html=True)
    
    # Metrics for quick question
    col1, col2, col3 = st.columns(3)
    with col1:
        confidence_emoji = "ğŸŸ¢" if confidence > 0.7 else "ğŸŸ¡" if confidence > 0.5 else "ğŸ”´"
        st.metric("Confidence", f"{confidence:.0%}", delta=confidence_emoji)
    with col2:
        st.metric("Response Time", f"{response_time:.2f}s")
    with col3:
        st.metric("Category", intent.title())
    
    # Rating for quick question - Enhanced UI with gradients
    st.markdown("**â­ Rate this response:**")
    
    # Create rating container with gradient background
    st.markdown('<div class="rating-container">', unsafe_allow_html=True)
    st.markdown('<div class="rating-title">â­ Rate this response:</div>', unsafe_allow_html=True)
    
    # Create unique key
    quick_id = f"quick_{len(st.session_state.conversation_history)}"
    quick_rating_key = f"rating_{quick_id}"
    
    # Initialize rating in session state
    if quick_rating_key not in st.session_state:
        st.session_state[quick_rating_key] = 0
    
    # Create 5 rating buttons with enhanced styling
    qcol1, qcol2, qcol3, qcol4, qcol5 = st.columns(5)
    
    with qcol1:
        if st.button("â­", key=f"qbtn1_{quick_id}", use_container_width=True, type="secondary"):
            st.session_state[quick_rating_key] = 1
    
    with qcol2:
        if st.button("â­â­", key=f"qbtn2_{quick_id}", use_container_width=True, type="secondary"):
            st.session_state[quick_rating_key] = 2
    
    with qcol3:
        if st.button("â­â­â­", key=f"qbtn3_{quick_id}", use_container_width=True, type="secondary"):
            st.session_state[quick_rating_key] = 3
    
    with qcol4:
        if st.button("â­â­â­â­", key=f"qbtn4_{quick_id}", use_container_width=True, type="secondary"):
            st.session_state[quick_rating_key] = 4
    
    with qcol5:
        if st.button("â­â­â­â­â­", key=f"qbtn5_{quick_id}", use_container_width=True, type="primary"):
            st.session_state[quick_rating_key] = 5
    
    st.markdown('</div>', unsafe_allow_html=True)
    
    # Get current rating
    rating = st.session_state[quick_rating_key]
    
    # Show feedback if rating was given
    if rating > 0:
        st.balloons()
        st.success(f"ğŸ‰ You rated: {rating} star{'s' if rating > 1 else ''}!")
        
        # Add to analytics
        st.session_state.analytics['user_ratings'].append(rating)
        
        # Enhanced feedback with matching colors
        descriptions = {1: "Poor", 2: "Fair", 3: "Good", 4: "Very Good", 5: "Excellent"}
        colors = {
            1: "linear-gradient(135deg, #ff6b6b 0%, #ee5a52 100%)",
            2: "linear-gradient(135deg, #ffa726 0%, #ff9800 100%)", 
            3: "linear-gradient(135deg, #ffeb3b 0%, #ffc107 100%)",
            4: "linear-gradient(135deg, #8bc34a 0%, #4caf50 100%)",
            5: "linear-gradient(135deg, #4caf50 0%, #2e7d32 100%)"
        }
        
        # Add bounce animation CSS first
        st.markdown("""
        <style>
        @keyframes bounce {
            0%, 20%, 50%, 80%, 100% { transform: scale(1.02) translateY(0); }
            40% { transform: scale(1.02) translateY(-10px); }
            60% { transform: scale(1.02) translateY(-5px); }
        }
        </style>
        """, unsafe_allow_html=True)
        
        # Then add the feedback box
        feedback_html = f"""
        <div style="
            background: {colors[rating]};
            color: white;
            padding: 2rem;
            border-radius: 20px;
            text-align: center;
            margin: 1rem 0;
            box-shadow: 0 15px 40px rgba(0,0,0,0.2);
            transform: scale(1.02);
            animation: bounce 0.6s ease-in-out;
        ">
            <h2 style="margin: 0; font-size: 1.5rem;">ğŸ‰ Thank you for your feedback!</h2>
            <div style="font-size: 3rem; margin: 1rem 0; text-shadow: 2px 2px 4px rgba(0,0,0,0.3);">
                {'â­' * rating}
            </div>
            <h3 style="margin: 0; font-size: 1.3rem;">
                You rated: <strong>{descriptions[rating]}</strong>
            </h3>
            <p style="font-size: 1rem; opacity: 0.9; margin-top: 0.5rem;">
                Your feedback helps us improve! ğŸš€
            </p>
        </div>
        """
        
        st.markdown(feedback_html, unsafe_allow_html=True)
        
        # Contextual message
        if rating >= 4:
            st.success("ğŸ¯ Awesome! We're thrilled you found our response helpful!")
        elif rating == 3:
            st.info("ğŸ‘ Thank you! We're always working to improve.")
        else:
            st.warning("ğŸ“ Thanks for the feedback! We'll work harder to help you better.")
    
    # Save to conversation history with current rating
    st.session_state.conversation_history.append({
        'question': st.session_state.temp_question,
        'answer': answer,
        'intent': intent,
        'confidence': confidence,
        'response_time': response_time,
        'rating': rating,
        'timestamp': datetime.now().isoformat()
    })
    
    del st.session_state.temp_question
    st.rerun()

# Notifications
st.sidebar.markdown("---")
st.sidebar.markdown(f'<div class="sidebar-section"><h3>{t["latest_updates"]}</h3></div>', unsafe_allow_html=True)

for i, notification in enumerate(t["notifications"]):
    if st.sidebar.button(notification, key=f"notif_{i}"):
        st.session_state.selected_notification = i

# Display notification details
if st.session_state.selected_notification is not None:
    detail = t["notification_details"][st.session_state.selected_notification]
    st.markdown(f'<div class="notification-detail">{detail}</div>', unsafe_allow_html=True)

# Resume upload
st.sidebar.markdown("---")
st.sidebar.markdown(f'<div class="sidebar-section"><h3>{t["upload_resume"]}</h3></div>', unsafe_allow_html=True)
uploaded_file = st.sidebar.file_uploader(t["upload_file"], type=['pdf', 'txt'], key="resume_upload")

if uploaded_file:
    resume_text = ""
    if uploaded_file.type == "text/plain":
        resume_text = str(uploaded_file.read(), "utf-8")
    elif uploaded_file.type == "application/pdf":
        resume_text = extract_text_from_pdf(uploaded_file)
    
    if resume_text and st.sidebar.button(t["get_suggestions"], key="get_suggestions"):
        suggestions = []
        resume_lower = resume_text.lower()
        
        if any(word in resume_lower for word in ['programming', 'coding', 'software', 'python', 'java']):
            suggestions.append("B.Tech Computer Science Engineering")
        if any(word in resume_lower for word in ['electronics', 'circuits', 'embedded']):
            suggestions.append("B.Tech Electronics & Communication")
        if any(word in resume_lower for word in ['management', 'business', 'marketing', 'finance']):
            suggestions.append("MBA")
        if any(word in resume_lower for word in ['mechanical', 'automobile', 'manufacturing']):
            suggestions.append("B.Tech Mechanical Engineering")
        
        if suggestions:
            st.sidebar.success(t["recommended_courses"])
            for course in suggestions:
                st.sidebar.write(f"â€¢ {course}")
        else:
            st.sidebar.info(t["upload_detailed"])

# Settings panel
st.sidebar.markdown("---")
with st.sidebar.expander("âš™ï¸ Settings", expanded=False):
    st.session_state.user_preferences['show_confidence'] = st.checkbox("Show Confidence Scores", 
                                                                      value=st.session_state.user_preferences.get('show_confidence', True))
    st.session_state.user_preferences['typing_animation'] = st.checkbox("Typing Animation", 
                                                                       value=st.session_state.user_preferences.get('typing_animation', True))
    st.session_state.user_preferences['auto_suggestions'] = st.checkbox("Auto Suggestions", 
                                                                        value=st.session_state.user_preferences.get('auto_suggestions', True))
    
    if st.button("ğŸ”„ Reset All Settings", key="reset_settings"):
        st.session_state.user_preferences = {
            'show_confidence': True,
            'typing_animation': True,
            'auto_suggestions': True
        }
        st.success("Settings reset!")

# Quick stats
st.sidebar.markdown("## ğŸ“ˆ Quick Stats")
stats_col1, stats_col2 = st.sidebar.columns(2)
with stats_col1:
    st.metric("Questions", st.session_state.analytics['questions_asked'])
    avg_rating = sum(st.session_state.analytics['user_ratings']) / len(st.session_state.analytics['user_ratings']) if st.session_state.analytics['user_ratings'] else 0
    st.metric("Avg Rating", f"{avg_rating:.1f}â­")
with stats_col2:
    session_duration = (datetime.now() - st.session_state.analytics['session_start']).seconds // 60
    st.metric("Session", f"{session_duration}m")
    if st.session_state.analytics['response_times']:
        avg_response = sum(st.session_state.analytics['response_times']) / len(st.session_state.analytics['response_times'])
        st.metric("Avg Speed", f"{avg_response:.1f}s")

# Quick actions
st.sidebar.markdown("## âš¡ Quick Actions")
if st.sidebar.button("ğŸ² Random Question", key="random_question_action"):
    if faq_data:
        random_qa = random.choice(faq_data)
        st.session_state.temp_question = random_qa['prompt']

if st.sidebar.button("ğŸ“Š Show Full Analytics", key="show_analytics_action"):
    st.session_state.show_analytics = True

if st.sidebar.button("ğŸ§¹ Clear All Data", key="clear_data_action"):
    if st.sidebar.button("âš ï¸ Confirm Clear All", type="secondary", key="confirm_clear_action"):
        st.session_state.conversation_history = []
        st.session_state.analytics = {
            'questions_asked': 0,
            'languages_used': {},
            'intents_detected': {},
            'user_ratings': [],
            'session_start': datetime.now(),
            'response_times': [],
            'satisfaction_scores': []
        }
        st.success("All data cleared!")
        st.rerun()

# Export functionality
if st.session_state.conversation_history:
    st.sidebar.markdown("## ğŸ“¥ Export Options")
    
    export_format = st.sidebar.selectbox("Format:", ["JSON", "CSV", "TXT"], key="export_format_select")
    
    if st.sidebar.button("ğŸ“¥ Export Chat", key="export_chat_action"):
        if export_format == "JSON":
            data = json.dumps(st.session_state.conversation_history, indent=2, ensure_ascii=False)
            st.sidebar.download_button(
                "Download JSON", 
                data, 
                f"chat_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json", 
                "application/json",
                key="download_json_btn"
            )
        elif export_format == "CSV":
            if PLOTLY_AVAILABLE:
                df = pd.DataFrame(st.session_state.conversation_history)
                csv_data = df.to_csv(index=False)
                st.sidebar.download_button(
                    "Download CSV", 
                    csv_data, 
                    f"chat_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv", 
                    "text/csv",
                    key="download_csv_btn"
                )
            else:
                st.sidebar.error("Pandas not available for CSV export")
        else:  # TXT
            txt_data = f"College Admission Chat History\nGenerated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n{'='*50}\n\n"
            for i, qa in enumerate(st.session_state.conversation_history, 1):
                txt_data += f"Q{i}: {qa['question']}\n"
                txt_data += f"A{i}: {qa['answer']}\n"
                txt_data += f"Category: {qa.get('intent', 'Unknown')}\n"
                txt_data += f"Confidence: {qa.get('confidence', 0):.0%}\n"
                txt_data += f"Rating: {'â­' * qa.get('rating', 0) if qa.get('rating') else 'No rating'}\n"
                txt_data += f"Time: {qa.get('timestamp', 'Unknown')}\n"
                txt_data += "="*50 + "\n\n"
            
            st.sidebar.download_button(
                "Download TXT", 
                txt_data, 
                f"chat_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt", 
                "text/plain",
                key="download_txt_btn"
            )

# Debug section
if st.sidebar.checkbox("ğŸ” Debug Mode", key="debug_mode_check"):
    st.sidebar.markdown("### Available Questions:")
    for i, item in enumerate(faq_data[:10]):  # Show first 10
        st.sidebar.text(f"{i+1}. {item['prompt'][:50]}...")
    
    if len(faq_data) > 10:
        st.sidebar.text(f"... and {len(faq_data) - 10} more questions")
    
    st.sidebar.markdown(f"**Total FAQ items:** {len(faq_data)}")

# Contact info
st.markdown("---")
st.markdown(t["contact_support"])
